{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd00110e3ad3d2995649b9eed0505b86961f21d80e4cfa55b9dc2096312fa84aa23",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "0110e3ad3d2995649b9eed0505b86961f21d80e4cfa55b9dc2096312fa84aa23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bayesian.train_bn import structure_learning, parameter_learning, parameter_learning_mix, n_component\n",
    "from preprocess.discretization import get_nodes_type, discretization, inverse_discretization, code_categories, get_nodes_sign\n",
    "from bayesian.save_bn import save_structure, save_params, read_structure, read_params\n",
    "from bayesian.sampling import generate_synthetics\n",
    "from external.libpgm.hybayesiannetwork import HyBayesianNetwork\n",
    "from visualization.visualization import draw_BN\n",
    "from bayesian.calculate_accuracy import calculate_acc\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from copy import copy\n",
    "from external.libpgm.sampleaggregator import SampleAggregator\n",
    "import operator\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from scipy import stats\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import math\n",
    "from pomegranate import DiscreteDistribution\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = geo = pd.read_csv('../data/hackathon_processed.csv')\n",
    "columns = ['Tectonic regime', 'Period', 'Lithology', 'Structural setting', 'Hydrocarbon type', 'Gross','Netpay','Porosity','Permeability', 'Depth']\n",
    "geo = geo[columns]\n",
    "geo.dropna(inplace=True)\n",
    "geo.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Tectonic regime': 'disc',\n",
       " 'Period': 'disc',\n",
       " 'Lithology': 'disc',\n",
       " 'Structural setting': 'disc',\n",
       " 'Hydrocarbon type': 'disc',\n",
       " 'Gross': 'cont',\n",
       " 'Netpay': 'cont',\n",
       " 'Porosity': 'cont',\n",
       " 'Permeability': 'cont',\n",
       " 'Depth': 'cont'}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "geo_types = get_nodes_type(geo)\n",
    "geo_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Gross': 'pos',\n",
       " 'Netpay': 'pos',\n",
       " 'Porosity': 'pos',\n",
       " 'Permeability': 'pos',\n",
       " 'Depth': 'pos'}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "geo_signs = get_nodes_sign(geo)\n",
    "geo_signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "colums_for_code = []\n",
    "columns_for_disc = []\n",
    "for c in columns:\n",
    "    if geo_types[c] == 'disc':\n",
    "        colums_for_code.append(c)\n",
    "    else:\n",
    "        columns_for_disc.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_coded, label_coder = code_categories(geo, 'label', colums_for_code)\n",
    "geo_discrete, coder = discretization(geo_coded, 'equal_frequency', columns_for_disc)\n",
    "geo_only_discrete, discrete_coder = discretization(geo, 'equal_frequency', columns_for_disc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'V': ['Tectonic regime',\n",
       "  'Period',\n",
       "  'Lithology',\n",
       "  'Structural setting',\n",
       "  'Hydrocarbon type',\n",
       "  'Gross',\n",
       "  'Netpay',\n",
       "  'Porosity',\n",
       "  'Permeability',\n",
       "  'Depth'],\n",
       " 'E': [['Hydrocarbon type', 'Tectonic regime'],\n",
       "  ['Hydrocarbon type', 'Period'],\n",
       "  ['Hydrocarbon type', 'Lithology'],\n",
       "  ['Period', 'Lithology'],\n",
       "  ['Structural setting', 'Lithology'],\n",
       "  ['Hydrocarbon type', 'Structural setting'],\n",
       "  ['Hydrocarbon type', 'Gross'],\n",
       "  ['Lithology', 'Gross'],\n",
       "  ['Porosity', 'Netpay'],\n",
       "  ['Gross', 'Porosity'],\n",
       "  ['Tectonic regime', 'Porosity'],\n",
       "  ['Gross', 'Permeability'],\n",
       "  ['Period', 'Depth'],\n",
       "  ['Lithology', 'Depth'],\n",
       "  ['Netpay', 'Depth']]}"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "accuracy_dict = dict()\n",
    "rmse_dict = dict()\n",
    "pred_param = [[0 for j in range(geo.shape[0])] for i in range(len(columns))]\n",
    "real_param = [[0 for j in range(geo.shape[0])] for i in range(len(columns))]\n",
    "for i in range (geo.shape[0]):\n",
    "    test = dict(geo.iloc[i,:])\n",
    "    train_data = geo_discrete.drop(index=i)\n",
    "    param_train = geo.drop(index=i)\n",
    "    train_data.reset_index(inplace=True, drop = True)\n",
    "    param_train.reset_index(inplace=True, drop = True)\n",
    "    bn = structure_learning(train_data, 'HC', geo_types, 'K2')\n",
    "    params = parameter_learning(param_train, geo_types, bn)\n",
    "    save_structure(bn, 'all_net')\n",
    "    skel = read_structure('all_net')\n",
    "    save_params(params, 'all_net_param')\n",
    "    params = read_params('all_net_param')\n",
    "    all_bn = HyBayesianNetwork(skel, params)\n",
    "    for n, key in enumerate(columns):\n",
    "        train_dict = copy(test)\n",
    "        train_dict.pop(key)\n",
    "        try:\n",
    "            sample = generate_synthetics(all_bn, geo_signs, evidence=train_dict)\n",
    "            if geo_types[key] == 'disc':\n",
    "                dict_top_probs = dict()\n",
    "                probs = dict(sample.groupby(key)[key].count() / sample.shape[0])\n",
    "                sorted_res = sorted(probs.items(), key=operator.itemgetter(1), reverse=True)\n",
    "                pred_param[n][i] = sorted_res[0][0]\n",
    "                real_param[n][i] = test[key]\n",
    "            if node_type[key] == 'cont':\n",
    "                pred_param[n][i] = np.mean(sample[key].values)\n",
    "                real_param[n][i] = test[key]\n",
    "        except:\n",
    "            continue\n",
    "for n, key in enumerate(columns):\n",
    "        if node_type[key] == 'disc':\n",
    "            accuracy_dict[key] = round(accuracy_score(real_param[n], pred_param[n]),2)\n",
    "        if node_type[key] == 'cont':\n",
    "            rmse_dict[key] = round(mean_squared_error(real_param[n], pred_param[n], squared=False),2)"
   ]
  }
 ]
}